{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Enter Ticker and Years back to search:**"
      ],
      "metadata": {
        "id": "wVCC6jwUQJ45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CONFIGURATION - CHANGE THESE VALUES\n",
        "# ============================================================\n",
        "\n",
        "COMPANY_TICKER = \"FCE\"        # Change to any ticker: \"JOBY\", \"CHRS\", \"AAPL\", etc.\n",
        "YEARS_BACK = 10                 # How many years back to search: 1, 2, 3, 5, etc.\n",
        "\n",
        "# CHANGE KEY IF NEEDED\n",
        "\n",
        "\n",
        "DEBUG = True"
      ],
      "metadata": {
        "id": "4cUNNnb3WFe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  Searching for names from these filings below:\n",
        "  \n",
        "\n",
        "*   Registration statements:     \"S-1\", \"S-3\", \"S-4\", \"S-8\", \"S-1/A\", \"S-3/A\", \"S-4/A\", \"S-8/A\",\"S-3ASR\", \"S-1MEF\", \"S-4MEF\",\"POS AM\", \"POSASR\"\n",
        "*   Prospectuses - ALL 424B types: \"424B1\", \"424B2\", \"424B3\", \"424B4\", \"424B5\", \"424B7\", \"424B8\"\n",
        "*   Private placements: \"D\", \"D/A\"\n",
        "*   M&A: \"SC TO-I\", \"SC TO-I/A\",\"SC 13E3\", \"SC 13E4\"\n",
        "*   Proxy: \"DEF 14A\", \"DEFA14A\", \"DEFM14A\"\n",
        "*   Foreign: \"F-1\", \"F-3\", \"F-1/A\", \"F-3/A\", \"CORRESP\"\n",
        "\n",
        "**Hit Run button Below**"
      ],
      "metadata": {
        "id": "6_R7zwutQWMA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PERFECTLY WORKING CODE"
      ],
      "metadata": {
        "id": "TGe1JUOZOUyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "from datetime import datetime, timedelta\n",
        "from collections import defaultdict\n",
        "\n",
        "LEGAL_COUNSEL_FILINGS = [\n",
        "    \"S-1\", \"S-3\", \"S-4\", \"S-8\",\n",
        "    \"S-1/A\", \"S-3/A\", \"S-4/A\", \"S-8/A\",\n",
        "    \"S-3ASR\", \"S-1MEF\", \"S-4MEF\",\n",
        "    \"POS AM\", \"POSASR\",\n",
        "    \"424B1\", \"424B2\", \"424B3\", \"424B4\", \"424B5\", \"424B7\", \"424B8\",\n",
        "    \"D\", \"D/A\",\n",
        "    \"SC TO-I\", \"SC TO-I/A\",\n",
        "    \"SC 13E3\", \"SC 13E4\",\n",
        "    \"DEF 14A\", \"DEFA14A\", \"DEFM14A\",\n",
        "    \"F-1\", \"F-3\", \"F-1/A\", \"F-3/A\",\n",
        "    \"CORRESP\", \"UPLOAD\", \"EX-24\"\n",
        "]\n",
        "\n",
        "def normalize_firm_name(firm):\n",
        "    firm = firm.strip()\n",
        "    firm = re.sub(r'\\s+and\\s+', ' & ', firm, flags=re.IGNORECASE)\n",
        "    firm = re.sub(r'\\s+', ' ', firm)\n",
        "    if not any(firm.endswith(suffix) for suffix in ['LLP', 'LLC', 'P.C.', 'P.A.']):\n",
        "        firm = firm + \" LLP\"\n",
        "    return firm\n",
        "\n",
        "def normalize_lawyer_name(name):\n",
        "    name = name.strip()\n",
        "    name = re.sub(r',?\\s*Esq\\.?', '', name, flags=re.IGNORECASE)\n",
        "    name = re.sub(r'\\s+', ' ', name)\n",
        "    return name.strip()\n",
        "\n",
        "def is_valid_person_name(name, company_name=None):\n",
        "    \"\"\"\n",
        "    Validate that this is actually a person's name, not a title or company name.\n",
        "    Returns True if valid, False if invalid.\n",
        "    \"\"\"\n",
        "    name_lower = name.lower()\n",
        "\n",
        "    # Filter out company name or parts of it\n",
        "    if company_name:\n",
        "        company_lower = company_name.lower()\n",
        "        # Check if the name contains significant parts of company name\n",
        "        company_words = set(company_lower.split())\n",
        "        name_words = set(name_lower.split())\n",
        "\n",
        "        # If name contains company-specific words like \"Enovix\", reject it\n",
        "        if any(word in company_words and len(word) > 4 for word in name_words):\n",
        "            return False\n",
        "\n",
        "    # Filter out obvious titles and non-name phrases\n",
        "    invalid_phrases = [\n",
        "        'legal officer', 'chief legal', 'general counsel', 'corporate counsel',\n",
        "        'secretary', 'president', 'vice president', 'chief executive',\n",
        "        'ceo', 'cfo', 'clo', 'officer', 'director', 'manager',\n",
        "        'associate', 'partner', 'attorney', 'lawyer', 'counsel',\n",
        "        'corporation', 'company', 'inc', 'llc', 'llp', 'limited',\n",
        "        'the registrant', 'the company', 'issuer'\n",
        "    ]\n",
        "\n",
        "    if any(phrase in name_lower for phrase in invalid_phrases):\n",
        "        return False\n",
        "\n",
        "    # Name should be 2-4 words\n",
        "    words = name.split()\n",
        "    if len(words) < 2 or len(words) > 4:\n",
        "        return False\n",
        "\n",
        "    # Each significant word should start with capital letter\n",
        "    # Allow middle initials like \"J.\" or single letters\n",
        "    for word in words:\n",
        "        if len(word) > 1 and not word[0].isupper():\n",
        "            return False\n",
        "\n",
        "    # At least one word should be longer than 3 characters (not just initials)\n",
        "    if not any(len(word) > 3 for word in words):\n",
        "        return False\n",
        "\n",
        "    # Filter out common non-name patterns\n",
        "    if name_lower.startswith('by ') or name_lower.startswith('for '):\n",
        "        return False\n",
        "\n",
        "    return True\n",
        "\n",
        "def is_internal_employee(name, text_near_name):\n",
        "    \"\"\"\n",
        "    Check if lawyer name appears with company title.\n",
        "    CRITICAL: Only check text BETWEEN the name and the firm, not after.\n",
        "    \"\"\"\n",
        "    internal_titles = [\n",
        "        'general counsel', 'chief legal officer', 'clo',\n",
        "        'corporate counsel', 'secretary', 'corporate secretary',\n",
        "        'in-house counsel', 'legal counsel', 'vice president',\n",
        "        'senior counsel', 'associate general counsel', 'president',\n",
        "        'chief executive', 'ceo', 'cfo'\n",
        "    ]\n",
        "\n",
        "    # Find where the name appears in the context\n",
        "    name_idx = text_near_name.find(name)\n",
        "    if name_idx == -1:\n",
        "        return False\n",
        "\n",
        "    # Only check the text BETWEEN the name and firm (next ~100 chars after name)\n",
        "    text_after_name = text_near_name[name_idx:name_idx + 100].lower()\n",
        "\n",
        "    return any(title in text_after_name for title in internal_titles)\n",
        "\n",
        "def is_not_law_firm(firm_name, company_name=None):\n",
        "    \"\"\"Filter out non-law-firms\"\"\"\n",
        "    firm_lower = firm_name.lower()\n",
        "\n",
        "    # Filter placeholder/garbage names\n",
        "    garbage_names = ['law_firms', 'lawyers', 'law firm', 'example', 'firm name', 'another']\n",
        "    if any(garbage in firm_lower for garbage in garbage_names):\n",
        "        return True\n",
        "\n",
        "    # Exclude the company itself\n",
        "    if company_name and company_name.lower() in firm_lower:\n",
        "        return True\n",
        "\n",
        "    # Accounting firms\n",
        "    accounting_patterns = [\n",
        "        r'\\bdeloitte\\b', r'\\bpwc\\b', r'\\bpricewaterhousecoopers\\b',\n",
        "        r'\\bernst\\s*&\\s*young\\b', r'\\bkpmg\\b', r'\\bey\\b'\n",
        "    ]\n",
        "    for pattern in accounting_patterns:\n",
        "        if re.search(pattern, firm_lower):\n",
        "            return True\n",
        "\n",
        "    # Investment banks/brokers\n",
        "    investment_banks = [\n",
        "        'goldman sachs', 'morgan stanley', 'jp morgan', 'jpmorgan',\n",
        "        'credit suisse', 'ubs', 'deutsche bank', 'barclays',\n",
        "        'cantor fitzgerald', 'oppenheimer', 'jefferies', 'cowen',\n",
        "        'stifel', 'piper sandler', 'raymond james', 'roth capital',\n",
        "        'needham', 'wedbush', 'craig-hallum', 'btig', \"maxim group\"\n",
        "    ]\n",
        "    if any(bank in firm_lower for bank in investment_banks):\n",
        "        return True\n",
        "\n",
        "    if '& co' in firm_lower and 'llp' not in firm_lower:\n",
        "        return True\n",
        "\n",
        "    fund_keywords = ['fund', 'capital', 'ventures', 'holdings', 'trust company']\n",
        "    if any(keyword in firm_lower for keyword in fund_keywords) and 'llc' in firm_lower and 'llp' not in firm_lower:\n",
        "        return True\n",
        "\n",
        "    return False\n",
        "\n",
        "def extract_lawyers_by_regex(text, company_name):\n",
        "    \"\"\"\n",
        "    Extract lawyer names using regex patterns for common formats.\n",
        "    \"\"\"\n",
        "    results = defaultdict(set)\n",
        "\n",
        "    # Pattern 1: \"Name and Name of Firm\" or \"Name, Name, and Name of Firm\"\n",
        "    pattern1 = r'([A-Z][a-z]+(?:\\s+[A-Z]\\.?)?\\s+[A-Z][a-z]+(?:\\s+(?:and|,)\\s+[A-Z][a-z]+(?:\\s+[A-Z]\\.?)?\\s+[A-Z][a-z]+)*)\\s+of\\s+([A-Z][^\\n]{5,60}?(?:LLP|LLC|P\\.C\\.|P\\.A\\.))'\n",
        "\n",
        "    matches = re.finditer(pattern1, text, re.MULTILINE)\n",
        "\n",
        "    for match in matches:\n",
        "        names_part = match.group(1)\n",
        "        firm = match.group(2).strip()\n",
        "\n",
        "        # Get context\n",
        "        context = text[max(0, match.start()-100):match.end()+100]\n",
        "\n",
        "        # Skip if not a real law firm\n",
        "        if is_not_law_firm(firm, company_name):\n",
        "            continue\n",
        "\n",
        "        # Split the names by \"and\" or \",\"\n",
        "        names = re.split(r'\\s+and\\s+|,\\s*', names_part)\n",
        "        names = [n.strip() for n in names if n.strip()]\n",
        "\n",
        "        # Validate names\n",
        "        valid_names = []\n",
        "        for name in names:\n",
        "            name = re.sub(r'^(Mr\\.|Ms\\.|Mrs\\.|Dr\\.)\\s+', '', name)\n",
        "            name = re.sub(r',?\\s*Esq\\.?$', '', name, flags=re.IGNORECASE)\n",
        "            name = name.strip()\n",
        "\n",
        "            # STRICT VALIDATION\n",
        "            if not is_valid_person_name(name, company_name):\n",
        "                continue\n",
        "\n",
        "            # Check if internal employee\n",
        "            if not is_internal_employee(name, context):\n",
        "                valid_names.append(name)\n",
        "\n",
        "        if valid_names:\n",
        "            normalized_firm = normalize_firm_name(firm)\n",
        "            for name in valid_names:\n",
        "                results[normalized_firm].add(normalize_lawyer_name(name))\n",
        "\n",
        "    # Pattern 2: \"Name\\nFirm LLP\" - name on one line, firm on next\n",
        "    pattern2 = r'([A-Z][a-z]+(?:\\s+[A-Z]\\.?)?\\s+[A-Z][a-z]+)\\s*\\n\\s*([A-Z][^\\n]{5,60}?(?:LLP|LLC|P\\.C\\.|P\\.A\\.))'\n",
        "\n",
        "    matches2 = re.finditer(pattern2, text, re.MULTILINE)\n",
        "\n",
        "    for match in matches2:\n",
        "        name = match.group(1).strip()\n",
        "        firm = match.group(2).strip()\n",
        "\n",
        "        context = text[match.start():match.end() + 100]\n",
        "\n",
        "        if is_not_law_firm(firm, company_name):\n",
        "            continue\n",
        "\n",
        "        # STRICT VALIDATION\n",
        "        if not is_valid_person_name(name, company_name):\n",
        "            continue\n",
        "\n",
        "        if not is_internal_employee(name, context):\n",
        "            normalized_firm = normalize_firm_name(firm)\n",
        "            results[normalized_firm].add(normalize_lawyer_name(name))\n",
        "\n",
        "    # Pattern 3: \"By: Name\\nFirm LLP\" signature blocks\n",
        "    pattern3 = r'By:\\s*([A-Z][a-z]+(?:\\s+[A-Z]\\.?)?\\s+[A-Z][a-z]+)\\s*\\n\\s*([A-Z][^\\n]{5,60}?(?:LLP|LLC|P\\.C\\.|P\\.A\\.))'\n",
        "\n",
        "    matches3 = re.finditer(pattern3, text, re.MULTILINE)\n",
        "\n",
        "    for match in matches3:\n",
        "        name = match.group(1).strip()\n",
        "        firm = match.group(2).strip()\n",
        "\n",
        "        context = text[match.start():match.end() + 100]\n",
        "\n",
        "        if is_not_law_firm(firm, company_name):\n",
        "            continue\n",
        "\n",
        "        # STRICT VALIDATION\n",
        "        if not is_valid_person_name(name, company_name):\n",
        "            continue\n",
        "\n",
        "        if not is_internal_employee(name, context):\n",
        "            normalized_firm = normalize_firm_name(firm)\n",
        "            results[normalized_firm].add(normalize_lawyer_name(name))\n",
        "\n",
        "    return results\n",
        "\n",
        "def get_cik_from_ticker(ticker):\n",
        "    ticker = ticker.replace(\" US Equity\", \"\").strip()\n",
        "    try:\n",
        "        url = \"https://www.sec.gov/files/company_tickers.json\"\n",
        "        headers = {\"User-Agent\": \"Company contact@email.com\"}\n",
        "        response = requests.get(url, headers=headers)\n",
        "        data = response.json()\n",
        "        ticker_upper = ticker.upper()\n",
        "\n",
        "        for key, company_info in data.items():\n",
        "            if company_info.get('ticker', '').upper() == ticker_upper:\n",
        "                cik = str(company_info['cik_str'])\n",
        "                company_name = company_info['title']\n",
        "                return cik, company_name\n",
        "    except Exception:\n",
        "        pass\n",
        "    return None, None\n",
        "\n",
        "def get_company_filings(cik, years_back):\n",
        "    url = f\"https://data.sec.gov/submissions/CIK{cik.zfill(10)}.json\"\n",
        "    headers = {\"User-Agent\": \"Company contact@email.com\"}\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers)\n",
        "        data = response.json()\n",
        "        filings = []\n",
        "        recent = data.get('filings', {}).get('recent', {})\n",
        "        cutoff_date = (datetime.now() - timedelta(days=years_back*365)).strftime('%Y-%m-%d')\n",
        "\n",
        "        for i in range(len(recent.get('form', []))):\n",
        "            filing_type = recent['form'][i]\n",
        "            filing_date = recent['filingDate'][i]\n",
        "\n",
        "            if filing_type in LEGAL_COUNSEL_FILINGS and filing_date >= cutoff_date:\n",
        "                filings.append({\n",
        "                    'type': filing_type,\n",
        "                    'date': filing_date,\n",
        "                    'accession': recent['accessionNumber'][i],\n",
        "                    'primary_doc': recent.get('primaryDocument', [None])[i] if i < len(recent.get('primaryDocument', [])) else None\n",
        "                })\n",
        "\n",
        "        filings.sort(key=lambda x: x['date'], reverse=True)\n",
        "        return filings\n",
        "    except Exception:\n",
        "        return []\n",
        "\n",
        "def extract_counsel_sections(doc_url):\n",
        "    headers = {\"User-Agent\": \"Company contact@email.com\"}\n",
        "\n",
        "    try:\n",
        "        response = requests.get(doc_url, headers=headers, timeout=20)\n",
        "        if response.status_code != 200:\n",
        "            return None\n",
        "\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        text = soup.get_text(separator='\\n')\n",
        "\n",
        "        if len(text) < 5000:\n",
        "            return None\n",
        "\n",
        "        return text[:25000]\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def parse_with_openai(text_sections, company_name, api_key, retries=2):\n",
        "    \"\"\"AI extraction with strict validation\"\"\"\n",
        "    if len(text_sections) > 15000:\n",
        "        text_sections = text_sections[:15000]\n",
        "\n",
        "    prompt = f\"\"\"Extract ONLY EXTERNAL law firm names and EXTERNAL lawyers from this SEC filing for {company_name}.\n",
        "\n",
        "CRITICAL RULES:\n",
        "1. ONLY extract PEOPLE'S NAMES - first and last names like \"John Smith\" or \"Jane K. Doe\"\n",
        "2. DO NOT extract:\n",
        "   - Titles like \"Legal Officer\", \"General Counsel\", \"Chief Legal Officer\"\n",
        "   - Company names like \"{company_name}\" or \"Corporation\"\n",
        "   - Generic terms like \"Attorney\", \"Counsel\", \"Lawyer\"\n",
        "   - Phrases like \"The Company\", \"The Registrant\"\n",
        "3. Find law firms ending in LLP, LLC, or P.C.\n",
        "4. EXCLUDE: Accounting firms (Deloitte, PwC, KPMG, EY)\n",
        "5. EXCLUDE: Investment banks (Goldman Sachs, Cantor Fitzgerald, etc.)\n",
        "6. ONLY include lawyers who work AT the law firm, NOT company employees\n",
        "\n",
        "WHAT A VALID NAME LOOKS LIKE:\n",
        "✓ \"John Smith\" - first + last name\n",
        "✓ \"Jane K. Doe\" - first + middle initial + last name\n",
        "✓ \"Robert Johnson III\" - first + last + suffix\n",
        "\n",
        "WHAT IS NOT A VALID NAME:\n",
        "✗ \"Legal Officer\" - this is a TITLE\n",
        "✗ \"{company_name}\" - this is a COMPANY NAME\n",
        "✗ \"Chief Legal Officer\" - this is a TITLE\n",
        "✗ \"General Counsel\" - this is a TITLE\n",
        "✗ \"Corporate Secretary\" - this is a TITLE\n",
        "\n",
        "PATTERNS TO LOOK FOR:\n",
        "\"Carlos Ramirez and Nicholaus Johnson of Cooley LLP\"\n",
        "-> {{\"Cooley LLP\": [\"Carlos Ramirez\", \"Nicholaus Johnson\"]}}\n",
        "\n",
        "\"First Name Last Name\n",
        "Law Firm Name LLP\"\n",
        "-> {{\"Law Firm Name LLP\": [\"First Name Last Name\"]}}\n",
        "\n",
        "Text:\n",
        "{text_sections}\n",
        "\n",
        "Return JSON with law firms and ONLY PERSON NAMES (not titles, not company names):\n",
        "{{\"Cooley LLP\": [\"John Smith\", \"Jane Doe\"]}}\"\"\"\n",
        "\n",
        "    for attempt in range(retries + 1):\n",
        "        try:\n",
        "            response = requests.post(\n",
        "                \"https://api.openai.com/v1/chat/completions\",\n",
        "                headers={\n",
        "                    \"Content-Type\": \"application/json\",\n",
        "                    \"Authorization\": f\"Bearer {api_key}\"\n",
        "                },\n",
        "                json={\n",
        "                    \"model\": \"gpt-4o-mini\",\n",
        "                    \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "                    \"temperature\": 0\n",
        "                },\n",
        "                timeout=30\n",
        "            )\n",
        "\n",
        "            result = response.json()\n",
        "\n",
        "            if 'choices' in result and len(result['choices']) > 0:\n",
        "                response_text = result['choices'][0]['message']['content']\n",
        "                response_text = re.sub(r'```json\\s*|\\s*```', '', response_text).strip()\n",
        "                data = json.loads(response_text)\n",
        "\n",
        "                filtered_data = {}\n",
        "                for firm, lawyers in data.items():\n",
        "                    if firm.lower() in ['firm a', 'firm b', 'example firm']:\n",
        "                        continue\n",
        "\n",
        "                    if not is_not_law_firm(firm, company_name):\n",
        "                        normalized_firm = normalize_firm_name(firm)\n",
        "\n",
        "                        # STRICT VALIDATION on each lawyer name\n",
        "                        normalized_lawyers = []\n",
        "                        for l in lawyers:\n",
        "                            if not l or not l.strip():\n",
        "                                continue\n",
        "\n",
        "                            # CRITICAL: Validate this is actually a person's name\n",
        "                            if not is_valid_person_name(l, company_name):\n",
        "                                continue\n",
        "\n",
        "                            # Check if internal employee\n",
        "                            if l in text_sections:\n",
        "                                idx = text_sections.find(l)\n",
        "                                context = text_sections[idx:idx+200]\n",
        "                                if is_internal_employee(l, context):\n",
        "                                    continue\n",
        "\n",
        "                            normalized_lawyers.append(normalize_lawyer_name(l))\n",
        "\n",
        "                        if normalized_lawyers:\n",
        "                            filtered_data[normalized_firm] = normalized_lawyers\n",
        "\n",
        "                return filtered_data\n",
        "        except Exception:\n",
        "            if attempt < retries:\n",
        "                continue\n",
        "\n",
        "    return {}\n",
        "\n",
        "def search_company_for_lawyers(company_ticker, years_back, api_key):\n",
        "    print(\"\\nStep 1: FINDING LAWYERS FOR:\", company_ticker)\n",
        "    print(f\"        SEARCHING LAST {years_back} YEAR(S)\")\n",
        "\n",
        "    cik, company_name = get_cik_from_ticker(company_ticker)\n",
        "    if not cik:\n",
        "        print(f\"\\nERROR: Company '{company_ticker}' not found\")\n",
        "        return None\n",
        "\n",
        "    print(f\"\\nStep 2: Getting filings from last {years_back} year(s)...\")\n",
        "    filings = get_company_filings(cik, years_back)\n",
        "\n",
        "    if not filings:\n",
        "        print(f\"        ERROR: No relevant filings found\")\n",
        "        return None\n",
        "\n",
        "    print(f\"        Found {len(filings)} total filings\")\n",
        "\n",
        "    if filings:\n",
        "        oldest_date = min(f['date'] for f in filings)\n",
        "        newest_date = max(f['date'] for f in filings)\n",
        "        print(f\"        Date range: {oldest_date} to {newest_date}\")\n",
        "\n",
        "    print(f\"\\nStep 3: Extracting and parsing {len(filings)} filings...\")\n",
        "\n",
        "    firm_to_lawyers = defaultdict(set)\n",
        "\n",
        "    for idx, filing in enumerate(filings, 1):\n",
        "        if idx % 10 == 0:\n",
        "            print(f\"        Progress: {idx}/{len(filings)} filings...\")\n",
        "\n",
        "        accession_no_dashes = filing['accession'].replace('-', '')\n",
        "\n",
        "        if filing['primary_doc']:\n",
        "            doc_url = f\"https://www.sec.gov/Archives/edgar/data/{cik}/{accession_no_dashes}/{filing['primary_doc']}\"\n",
        "        else:\n",
        "            doc_url = f\"https://www.sec.gov/Archives/edgar/data/{cik}/{accession_no_dashes}/{filing['accession']}.htm\"\n",
        "\n",
        "        extracted_text = extract_counsel_sections(doc_url)\n",
        "\n",
        "        if extracted_text:\n",
        "            # First: Use regex to catch common patterns\n",
        "            regex_results = extract_lawyers_by_regex(extracted_text, company_name)\n",
        "            for firm, lawyers in regex_results.items():\n",
        "                firm_to_lawyers[firm].update(lawyers)\n",
        "\n",
        "            # Second: Use AI for anything regex might have missed\n",
        "            firm_lawyers_dict = parse_with_openai(extracted_text, company_name, api_key)\n",
        "\n",
        "            for firm, lawyers in firm_lawyers_dict.items():\n",
        "                firm_to_lawyers[firm].update(lawyers)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"RESULTS\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"\\nCompany: {company_name}\")\n",
        "    print(f\"Checked: {len(filings)} filings\\n\")\n",
        "\n",
        "    if not firm_to_lawyers:\n",
        "        print(\"No law firms found\\n\")\n",
        "        return None\n",
        "\n",
        "    for firm in sorted(firm_to_lawyers.keys()):\n",
        "        lawyers = sorted(firm_to_lawyers[firm])\n",
        "        if lawyers:\n",
        "            print(f\"{firm}: {', '.join(lawyers)}\")\n",
        "        else:\n",
        "            print(f\"{firm}: (no lawyers identified)\")\n",
        "\n",
        "    results = []\n",
        "    for firm, lawyers in firm_to_lawyers.items():\n",
        "        if lawyers:\n",
        "            for lawyer in lawyers:\n",
        "                results.append({'Law_Firm': firm, 'Lawyer': lawyer})\n",
        "        else:\n",
        "            results.append({'Law_Firm': firm, 'Lawyer': ''})\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "    filename = f\"{company_ticker.lower().replace(' ', '_')}_lawyers.csv\"\n",
        "    df.to_csv(filename, index=False)\n",
        "    print(f\"\\nSaved to: {filename}\\n\")\n",
        "    return df\n",
        "\n",
        "# Example usage:\n",
        "result = search_company_for_lawyers(COMPANY_TICKER, YEARS_BACK, OPENAI_API_KEY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOimahtz-Em5",
        "outputId": "4cd4cc78-3f38-4fdf-fef0-c89cfe9c0477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step 1: FINDING LAWYERS FOR: FCE\n",
            "        SEARCHING LAST 10 YEAR(S)\n",
            "\n",
            "ERROR: Company 'FCE' not found\n"
          ]
        }
      ]
    }
  ]
}