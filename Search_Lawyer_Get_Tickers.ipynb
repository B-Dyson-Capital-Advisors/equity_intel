{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import requests\n","import pandas as pd\n","import time\n","import re\n","from datetime import datetime, timedelta\n","\n","# ============================================================\n","# CONFIGURATION\n","# ============================================================\n","\n","SEC_SEARCH_URL = \"https://efts.sec.gov/LATEST/search-index\"\n","\n","HEADERS = {\n","    \"User-Agent\": \"B. Dyson Capital Advisors contact@bdysoncapital.com\",\n","    \"Accept-Encoding\": \"gzip, deflate\",\n","    \"Host\": \"efts.sec.gov\"\n","}\n","\n","# Comprehensive filing types\n","COMPREHENSIVE_FILINGS = [\n","    # Core capital raising\n","    \"S-1\", \"S-3\", \"S-4\", \"S-8\",\n","    \"S-1/A\", \"S-3/A\", \"S-4/A\", \"S-8/A\",\n","    \"S-3ASR\", \"S-1MEF\", \"S-4MEF\",\n","    \"POS AM\", \"POSASR\",\n","\n","    # Prospectuses\n","    \"424B1\", \"424B3\", \"424B5\",\n","\n","    # Private placements\n","    \"D\", \"D/A\",\n","\n","    # M&A work\n","    \"SC TO-I\", \"SC TO-I/A\",\n","    \"SC 13E3\", \"SC 13E4\",\n","\n","    # Governance/proxy\n","    \"DEF 14A\", \"DEFA14A\",\n","    \"DEFM14A\",\n","\n","    # Material events\n","    \"8-K\", \"8-K/A\",\n","\n","    # Financial reports\n","    \"10-K\", \"10-Q\", \"10-K/A\", \"10-Q/A\",\n","\n","    # Investor filings\n","    \"SC 13D\", \"SC 13G\", \"SC 13D/A\", \"SC 13G/A\",\n","\n","    # Registration effectiveness\n","    \"EFFECT\",\n","]\n","\n","TARGET_COMPANIES = 100\n","\n","# ============================================================\n","# HELPER FUNCTIONS\n","# ============================================================\n","\n","def extract_ticker_and_clean_name(company_name):\n","    \"\"\"Extract ticker from company name\"\"\"\n","    name_without_cik = re.sub(r'\\s*\\(CIK\\s+\\d+\\)', '', company_name)\n","    ticker_match = re.search(r'\\(([A-Z0-9\\-]+)', name_without_cik)\n","    ticker = ticker_match.group(1) if ticker_match else \"\"\n","    clean_name = re.split(r'\\s*\\(', name_without_cik)[0].strip()\n","    return clean_name, ticker\n","\n","# ============================================================\n","# SEARCH FUNCTIONS\n","# ============================================================\n","\n","def search_edgar(search_term, from_date, to_date, start_index=0, max_results=100):\n","    \"\"\"Search SEC EDGAR\"\"\"\n","    results = []\n","    from_str = from_date.strftime(\"%Y-%m-%d\")\n","    to_str = to_date.strftime(\"%Y-%m-%d\")\n","\n","    params = {\n","        \"q\": f'\"{search_term}\"',\n","        \"dateRange\": \"custom\",\n","        \"startdt\": from_str,\n","        \"enddt\": to_str,\n","        \"from\": start_index,\n","        \"size\": min(max_results, 100)\n","    }\n","\n","    try:\n","        response = requests.get(SEC_SEARCH_URL, params=params, headers=HEADERS)\n","        response.raise_for_status()\n","        data = response.json()\n","\n","        if \"hits\" in data and \"hits\" in data[\"hits\"]:\n","            total_hits = data[\"hits\"][\"total\"][\"value\"]\n","\n","            for hit in data[\"hits\"][\"hits\"]:\n","                source = hit.get(\"_source\", {})\n","                filing_info = {\n","                    \"search_term\": search_term,\n","                    \"company_name\": source.get(\"display_names\", [\"Unknown\"])[0] if source.get(\"display_names\") else \"Unknown\",\n","                    \"filing_type\": source.get(\"file_type\", \"\"),\n","                    \"filing_date\": source.get(\"file_date\", \"\"),\n","                }\n","                results.append(filing_info)\n","\n","            return results, total_hits\n","\n","    except requests.exceptions.RequestException as e:\n","        print(f\"Error searching: {e}\")\n","\n","    time.sleep(0.15)\n","    return results, 0\n","\n","def search_paginated(search_term, from_date, to_date, max_total=500):\n","    \"\"\"Search with pagination\"\"\"\n","    all_results = []\n","    start_index = 0\n","    page_size = 100\n","\n","    while len(all_results) < max_total:\n","        results, total = search_edgar(search_term, from_date, to_date, start_index, page_size)\n","        if not results:\n","            break\n","        all_results.extend(results)\n","        start_index += page_size\n","        if len(all_results) >= total:\n","            break\n","\n","    return all_results, total\n","\n","def count_unique_companies(search_term, from_date, to_date):\n","    \"\"\"Count unique companies in a date range\"\"\"\n","    results, _ = search_paginated(search_term, from_date, to_date, max_total=500)\n","\n","    if not results:\n","        return 0\n","\n","    df = pd.DataFrame(results)\n","\n","    # Filter to comprehensive filing types\n","    df_filtered = df[df[\"filing_type\"].isin(COMPREHENSIVE_FILINGS)].copy()\n","\n","    # Extract company names\n","    df_filtered[['clean_company_name', 'ticker']] = df_filtered['company_name'].apply(\n","        lambda x: pd.Series(extract_ticker_and_clean_name(x))\n","    )\n","\n","    # Count unique companies with tickers\n","    unique_with_tickers = df_filtered[df_filtered['ticker'] != '']['clean_company_name'].nunique()\n","\n","    return unique_with_tickers\n","\n","def determine_optimal_date_range(search_term):\n","    \"\"\"\n","    Adaptive date range to keep results under 100 companies\n","    Options: 2 years, 3-5 years, 6-8 years\n","    \"\"\"\n","    end_date = datetime.now()\n","\n","    print(f\"\\nTesting volume for '{search_term}'...\")\n","\n","    # Test 2 years first\n","    test_2yr = end_date - timedelta(days=730)\n","    count_2yr = count_unique_companies(search_term, test_2yr, end_date)\n","    print(f\"  2 years: {count_2yr} unique companies\")\n","\n","    # Decide based on 2-year count\n","    if count_2yr >= TARGET_COMPANIES:\n","        # High volume - use 2 years\n","        days = 730\n","        final_range = \"2 years\"\n","        print(f\"HIGH VOLUME - Using 2 years\")\n","    elif count_2yr >= 40:\n","        # Good range - use 2 years\n","        days = 730\n","        final_range = \"2 years\"\n","        print(f\"OPTIMAL VOLUME - Using 2 years\")\n","    else:\n","        # Test 4 years\n","        test_4yr = end_date - timedelta(days=1460)\n","        count_4yr = count_unique_companies(search_term, test_4yr, end_date)\n","        print(f\"  4 years: {count_4yr} unique companies\")\n","\n","        if count_4yr >= TARGET_COMPANIES:\n","            # Use 3 years\n","            days = 1095\n","            final_range = \"3 years\"\n","            print(f\"MEDIUM-HIGH VOLUME - Using 3 years\")\n","        elif count_4yr >= 30:\n","            # Use 4 years\n","            days = 1460\n","            final_range = \"4 years\"\n","            print(f\"MEDIUM VOLUME - Using 4 years\")\n","        elif count_4yr >= 15:\n","            # Use 5 years\n","            days = 1825\n","            final_range = \"5 years\"\n","            print(f\"MEDIUM VOLUME - Using 5 years\")\n","        else:\n","            # Low volume - use 7 years\n","            days = 2555\n","            final_range = \"7 years\"\n","            print(f\"LOW VOLUME - Using 7 years for better coverage\")\n","\n","    start_date = end_date - timedelta(days=days)\n","    return start_date, end_date, final_range\n","\n","def filter_important_filings(df):\n","    \"\"\"Filter for comprehensive filing types\"\"\"\n","    if df.empty:\n","        return df\n","    return df[df[\"filing_type\"].isin(COMPREHENSIVE_FILINGS)].copy()\n","\n","def deduplicate_companies(df):\n","    \"\"\"Keep only most recent filing per company\"\"\"\n","    if df.empty:\n","        return df\n","    df = df.sort_values('filing_date', ascending=False)\n","    df_unique = df.drop_duplicates(subset=['clean_company_name'], keep='first')\n","    return df_unique\n","\n","# ============================================================\n","# MAIN SEARCH FUNCTION\n","# ============================================================\n","\n","def search_lawyer(lawyer_name):\n","    \"\"\"\n","    Search for companies represented by a lawyer\n","    Adaptively adjusts date range to keep under 100 companies\n","    \"\"\"\n","\n","    print(\"=\" * 70)\n","    print(f\"SEARCHING LAWYER: {lawyer_name}\")\n","    print(\"=\" * 70)\n","\n","    # Determine optimal date range\n","    start_date, end_date, date_range_desc = determine_optimal_date_range(lawyer_name)\n","\n","    print(f\"\\nFinal search: {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')} ({date_range_desc})\")\n","\n","    # Search with determined date range\n","    results, total = search_paginated(lawyer_name, start_date, end_date, max_total=500)\n","\n","    if not results:\n","        print(\"No results found.\")\n","        return pd.DataFrame()\n","\n","    df = pd.DataFrame(results)\n","    print(f\"\\nTotal filings found: {len(df)}\")\n","\n","    # Filter to comprehensive filing types\n","    df_filtered = filter_important_filings(df)\n","    print(f\"After filtering to relevant filing types: {len(df_filtered)}\")\n","\n","    if df_filtered.empty:\n","        print(\"No relevant filings after filtering.\")\n","        return pd.DataFrame()\n","\n","    # Extract ticker and clean name\n","    df_filtered[['clean_company_name', 'ticker']] = df_filtered['company_name'].apply(\n","        lambda x: pd.Series(extract_ticker_and_clean_name(x))\n","    )\n","\n","    # Convert dates\n","    df_filtered['filing_date'] = pd.to_datetime(df_filtered['filing_date'])\n","\n","    # Deduplicate\n","    df_unique = deduplicate_companies(df_filtered)\n","    print(f\"Unique companies: {len(df_unique)}\")\n","\n","    # Sort by most recent\n","    df_unique = df_unique.sort_values('filing_date', ascending=False)\n","\n","    # Keep only relevant columns\n","    result_df = df_unique[['clean_company_name', 'ticker']].copy()\n","    result_df.columns = ['Company', 'Ticker']\n","\n","    # Remove companies without tickers\n","    result_df = result_df[result_df['Ticker'] != \"\"].copy()\n","\n","    print(f\"\\n✓ Search complete: {len(result_df)} companies with tickers\")\n","\n","    return result_df\n","\n","# ============================================================\n","# EXPORT FUNCTION\n","# ============================================================\n","\n","# TICKERS ONLY\n","# def export_tickers_csv(df, filename):\n","#     \"\"\"Export single-column CSV with Bloomberg tickers\"\"\"\n","#     if df.empty:\n","#         print(\"\\nDataFrame is empty, nothing to export.\")\n","#         return []\n","\n","#     # Get unique tickers\n","#     tickers = df['Ticker'].dropna().unique()\n","#     tickers = [t for t in tickers if t != \"\" and t != \"Private\"]\n","\n","#     if len(tickers) == 0:\n","#         print(\"\\nNo valid tickers to export.\")\n","#         return []\n","\n","#     # Create Bloomberg format\n","#     bloomberg_tickers = [f\"{ticker} US Equity\" for ticker in tickers]\n","\n","#     # Create single-column DataFrame\n","#     export_df = pd.DataFrame({'Ticker': bloomberg_tickers})\n","\n","#     # Export to CSV\n","#     export_df.to_csv(filename, index=False)\n","\n","#     print(f\"\\n✓ Exported to: {filename}\")\n","#     print(f\"✓ Total tickers: {len(bloomberg_tickers)}\")\n","#     print(f\"\\nFirst 5 tickers:\")\n","#     for ticker in bloomberg_tickers[:5]:\n","#         print(f\"  {ticker}\")\n","\n","#     return bloomberg_tickers\n","\n","# NAMES AND TICKERS\n","def export_tickers_csv(df, filename):\n","    \"\"\"Export CSV with company names, Bloomberg tickers, and most recent filing date\"\"\"\n","    if df.empty:\n","        print(\"\\nDataFrame is empty, nothing to export.\")\n","        return []\n","\n","    # Remove rows without valid tickers\n","    df_valid = df[\n","        (df['Ticker'].notna()) &\n","        (df['Ticker'] != \"\") &\n","        (df['Ticker'] != \"Private\")\n","    ].copy()\n","\n","    if len(df_valid) == 0:\n","        print(\"\\nNo valid tickers to export.\")\n","        return []\n","\n","    # Create Bloomberg format ticker column\n","    df_valid['Bloomberg_Ticker'] = df_valid['Ticker'].apply(lambda x: f\"{x} US Equity\")\n","\n","    # Create export DataFrame with Company, Bloomberg Ticker, and Filing Date\n","    export_df = df_valid[['Company', 'Bloomberg_Ticker', 'filing_date']].copy()\n","    export_df.columns = ['Company', 'Ticker', 'Date of most recent filing for this company']\n","\n","    # Format the date column (convert to just date, no time)\n","    export_df['Date of most recent filing for this company'] = pd.to_datetime(\n","        export_df['Date of most recent filing for this company']\n","    ).dt.strftime('%Y-%m-%d')\n","\n","    # Sort alphabetically by ticker\n","    export_df = export_df.sort_values('Ticker')\n","\n","    # Export to CSV\n","    export_df.to_csv(filename, index=False)\n","\n","    print(f\"\\n✓ Exported to: {filename}\")\n","    print(f\"✓ Total companies: {len(export_df)}\")\n","    print(f\"\\nFirst 5 entries:\")\n","    print(export_df.head().to_string(index=False))\n","\n","    return export_df['Ticker'].tolist()"],"metadata":{"id":"_UKtVrNAb2aB","executionInfo":{"status":"ok","timestamp":1768930939397,"user_tz":300,"elapsed":34,"user":{"displayName":"Brendan Dyson","userId":"17814213712681171988"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import requests\n","import pandas as pd\n","import time\n","import re\n","from datetime import datetime, timedelta\n","\n","# ============================================================\n","# CONFIGURATION\n","# ============================================================\n","\n","SEC_SEARCH_URL = \"https://efts.sec.gov/LATEST/search-index\"\n","\n","HEADERS = {\n","    \"User-Agent\": \"B. Dyson Capital Advisors contact@bdysoncapital.com\",\n","    \"Accept-Encoding\": \"gzip, deflate\",\n","    \"Host\": \"efts.sec.gov\"\n","}\n","\n","# Comprehensive filing types\n","COMPREHENSIVE_FILINGS = [\n","    # Core capital raising\n","    \"S-1\", \"S-3\", \"S-4\", \"S-8\",\n","    \"S-1/A\", \"S-3/A\", \"S-4/A\", \"S-8/A\",\n","    \"S-3ASR\", \"S-1MEF\", \"S-4MEF\",\n","    \"POS AM\", \"POSASR\",\n","\n","    # Prospectuses\n","    \"424B1\", \"424B3\", \"424B5\",\n","\n","    # Private placements\n","    \"D\", \"D/A\",\n","\n","    # M&A work\n","    \"SC TO-I\", \"SC TO-I/A\",\n","    \"SC 13E3\", \"SC 13E4\",\n","\n","    # Governance/proxy\n","    \"DEF 14A\", \"DEFA14A\",\n","    \"DEFM14A\",\n","\n","    # Material events\n","    \"8-K\", \"8-K/A\",\n","\n","    # Financial reports\n","    \"10-K\", \"10-Q\", \"10-K/A\", \"10-Q/A\",\n","\n","    # Investor filings\n","    \"SC 13D\", \"SC 13G\", \"SC 13D/A\", \"SC 13G/A\",\n","\n","    # Registration effectiveness\n","    \"EFFECT\",\n","]\n","\n","TARGET_COMPANIES = 100\n","\n","# ============================================================\n","# HELPER FUNCTIONS\n","# ============================================================\n","\n","def extract_ticker_and_clean_name(company_name):\n","    \"\"\"Extract ticker from company name\"\"\"\n","    name_without_cik = re.sub(r'\\s*\\(CIK\\s+\\d+\\)', '', company_name)\n","    ticker_match = re.search(r'\\(([A-Z0-9\\-]+)', name_without_cik)\n","    ticker = ticker_match.group(1) if ticker_match else \"\"\n","    clean_name = re.split(r'\\s*\\(', name_without_cik)[0].strip()\n","    return clean_name, ticker\n","\n","# ============================================================\n","# SEARCH FUNCTIONS\n","# ============================================================\n","\n","def search_edgar(search_term, from_date, to_date, start_index=0, max_results=100):\n","    \"\"\"Search SEC EDGAR\"\"\"\n","    results = []\n","    from_str = from_date.strftime(\"%Y-%m-%d\")\n","    to_str = to_date.strftime(\"%Y-%m-%d\")\n","\n","    params = {\n","        \"q\": f'\"{search_term}\"',\n","        \"dateRange\": \"custom\",\n","        \"startdt\": from_str,\n","        \"enddt\": to_str,\n","        \"from\": start_index,\n","        \"size\": min(max_results, 100)\n","    }\n","\n","    try:\n","        response = requests.get(SEC_SEARCH_URL, params=params, headers=HEADERS)\n","        response.raise_for_status()\n","        data = response.json()\n","\n","        if \"hits\" in data and \"hits\" in data[\"hits\"]:\n","            total_hits = data[\"hits\"][\"total\"][\"value\"]\n","\n","            for hit in data[\"hits\"][\"hits\"]:\n","                source = hit.get(\"_source\", {})\n","                filing_info = {\n","                    \"search_term\": search_term,\n","                    \"company_name\": source.get(\"display_names\", [\"Unknown\"])[0] if source.get(\"display_names\") else \"Unknown\",\n","                    \"filing_type\": source.get(\"file_type\", \"\"),\n","                    \"filing_date\": source.get(\"file_date\", \"\"),\n","                }\n","                results.append(filing_info)\n","\n","            return results, total_hits\n","\n","    except requests.exceptions.RequestException as e:\n","        print(f\"Error searching: {e}\")\n","\n","    time.sleep(0.15)\n","    return results, 0\n","\n","def search_paginated(search_term, from_date, to_date, max_total=500):\n","    \"\"\"Search with pagination\"\"\"\n","    all_results = []\n","    start_index = 0\n","    page_size = 100\n","\n","    while len(all_results) < max_total:\n","        results, total = search_edgar(search_term, from_date, to_date, start_index, page_size)\n","        if not results:\n","            break\n","        all_results.extend(results)\n","        start_index += page_size\n","        if len(all_results) >= total:\n","            break\n","\n","    return all_results, total\n","\n","def count_unique_companies(search_term, from_date, to_date):\n","    \"\"\"Count unique companies in a date range\"\"\"\n","    results, _ = search_paginated(search_term, from_date, to_date, max_total=500)\n","\n","    if not results:\n","        return 0\n","\n","    df = pd.DataFrame(results)\n","\n","    # Filter to comprehensive filing types\n","    df_filtered = df[df[\"filing_type\"].isin(COMPREHENSIVE_FILINGS)].copy()\n","\n","    # Extract company names\n","    df_filtered[['clean_company_name', 'ticker']] = df_filtered['company_name'].apply(\n","        lambda x: pd.Series(extract_ticker_and_clean_name(x))\n","    )\n","\n","    # Count unique companies with tickers\n","    unique_with_tickers = df_filtered[df_filtered['ticker'] != '']['clean_company_name'].nunique()\n","\n","    return unique_with_tickers\n","\n","def determine_optimal_date_range(search_term):\n","    \"\"\"\n","    Adaptive date range to keep results under 100 companies\n","    Options: 2 years, 3-5 years, 6-8 years\n","    \"\"\"\n","    end_date = datetime.now()\n","\n","    print(f\"\\nTesting volume for '{search_term}'...\")\n","\n","    # Test 2 years first\n","    test_2yr = end_date - timedelta(days=730)\n","    count_2yr = count_unique_companies(search_term, test_2yr, end_date)\n","    print(f\"  2 years: {count_2yr} unique companies\")\n","\n","    # Decide based on 2-year count\n","    if count_2yr >= TARGET_COMPANIES:\n","        # High volume - use 2 years\n","        days = 730\n","        final_range = \"2 years\"\n","        print(f\"HIGH VOLUME - Using 2 years\")\n","    elif count_2yr >= 40:\n","        # Good range - use 2 years\n","        days = 730\n","        final_range = \"2 years\"\n","        print(f\"OPTIMAL VOLUME - Using 2 years\")\n","    else:\n","        # Test 4 years\n","        test_4yr = end_date - timedelta(days=1460)\n","        count_4yr = count_unique_companies(search_term, test_4yr, end_date)\n","        print(f\"  4 years: {count_4yr} unique companies\")\n","\n","        if count_4yr >= TARGET_COMPANIES:\n","            # Use 3 years\n","            days = 1095\n","            final_range = \"3 years\"\n","            print(f\"MEDIUM-HIGH VOLUME - Using 3 years\")\n","        elif count_4yr >= 30:\n","            # Use 4 years\n","            days = 1460\n","            final_range = \"4 years\"\n","            print(f\"MEDIUM VOLUME - Using 4 years\")\n","        elif count_4yr >= 15:\n","            # Use 5 years\n","            days = 1825\n","            final_range = \"5 years\"\n","            print(f\"MEDIUM VOLUME - Using 5 years\")\n","        else:\n","            # Low volume - use 7 years\n","            days = 2555\n","            final_range = \"7 years\"\n","            print(f\"LOW VOLUME - Using 7 years for better coverage\")\n","\n","    start_date = end_date - timedelta(days=days)\n","    return start_date, end_date, final_range\n","\n","def filter_important_filings(df):\n","    \"\"\"Filter for comprehensive filing types\"\"\"\n","    if df.empty:\n","        return df\n","    return df[df[\"filing_type\"].isin(COMPREHENSIVE_FILINGS)].copy()\n","\n","def deduplicate_companies(df):\n","    \"\"\"Keep only most recent filing per company\"\"\"\n","    if df.empty:\n","        return df\n","    df = df.sort_values('filing_date', ascending=False)\n","    df_unique = df.drop_duplicates(subset=['clean_company_name'], keep='first')\n","    return df_unique\n","\n","# ============================================================\n","# MAIN SEARCH FUNCTION\n","# ============================================================\n","\n","def search_lawyer(lawyer_name):\n","    \"\"\"\n","    Search for companies represented by a lawyer\n","    Adaptively adjusts date range to keep under 100 companies\n","    \"\"\"\n","\n","    print(\"=\" * 70)\n","    print(f\"SEARCHING LAWYER: {lawyer_name}\")\n","    print(\"=\" * 70)\n","\n","    # Determine optimal date range\n","    start_date, end_date, date_range_desc = determine_optimal_date_range(lawyer_name)\n","\n","    print(f\"\\nFinal search: {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')} ({date_range_desc})\")\n","\n","    # Search with determined date range\n","    results, total = search_paginated(lawyer_name, start_date, end_date, max_total=500)\n","\n","    if not results:\n","        print(\"No results found.\")\n","        return pd.DataFrame()\n","\n","    df = pd.DataFrame(results)\n","    print(f\"\\nTotal filings found: {len(df)}\")\n","\n","    # Filter to comprehensive filing types\n","    df_filtered = filter_important_filings(df)\n","    print(f\"After filtering to relevant filing types: {len(df_filtered)}\")\n","\n","    if df_filtered.empty:\n","        print(\"No relevant filings after filtering.\")\n","        return pd.DataFrame()\n","\n","    # Extract ticker and clean name\n","    df_filtered[['clean_company_name', 'ticker']] = df_filtered['company_name'].apply(\n","        lambda x: pd.Series(extract_ticker_and_clean_name(x))\n","    )\n","\n","    # Convert dates\n","    df_filtered['filing_date'] = pd.to_datetime(df_filtered['filing_date'])\n","\n","    # Deduplicate\n","    df_unique = deduplicate_companies(df_filtered)\n","    print(f\"Unique companies: {len(df_unique)}\")\n","\n","    # Sort by most recent\n","    df_unique = df_unique.sort_values('filing_date', ascending=False)\n","\n","    # Keep only relevant columns (include filing_date)\n","    result_df = df_unique[['clean_company_name', 'ticker', 'filing_date']].copy()\n","    result_df.columns = ['Company', 'Ticker', 'filing_date']\n","\n","    # Remove companies without tickers\n","    result_df = result_df[result_df['Ticker'] != \"\"].copy()\n","\n","    print(f\"\\n✓ Search complete: {len(result_df)} companies with tickers\")\n","\n","    return result_df\n","\n","# ============================================================\n","# EXPORT FUNCTION\n","# ============================================================\n","\n","def export_tickers_csv(df, filename):\n","    \"\"\"Export CSV with company names, Bloomberg tickers, and most recent filing date\"\"\"\n","    if df.empty:\n","        print(\"\\nDataFrame is empty, nothing to export.\")\n","        return []\n","\n","    # Remove rows without valid tickers\n","    df_valid = df[\n","        (df['Ticker'].notna()) &\n","        (df['Ticker'] != \"\") &\n","        (df['Ticker'] != \"Private\")\n","    ].copy()\n","\n","    if len(df_valid) == 0:\n","        print(\"\\nNo valid tickers to export.\")\n","        return []\n","\n","    # Create Bloomberg format ticker column\n","    df_valid['Bloomberg_Ticker'] = df_valid['Ticker'].apply(lambda x: f\"{x} US Equity\")\n","\n","    # Create export DataFrame with Company, Bloomberg Ticker, and Filing Date\n","    export_df = df_valid[['Company', 'Bloomberg_Ticker', 'filing_date']].copy()\n","    export_df.columns = ['Company', 'Ticker', 'Date of most recent filing for this company']\n","\n","    # Format the date column (convert to just date, no time)\n","    export_df['Date of most recent filing for this company'] = pd.to_datetime(\n","        export_df['Date of most recent filing for this company']\n","    ).dt.strftime('%Y-%m-%d')\n","\n","    # Sort alphabetically by ticker\n","    export_df = export_df.sort_values('Ticker')\n","\n","    # Export to CSV\n","    export_df.to_csv(filename, index=False)\n","\n","    print(f\"\\n✓ Exported to: {filename}\")\n","    print(f\"✓ Total companies: {len(export_df)}\")\n","    print(f\"\\nFirst 5 entries:\")\n","    print(export_df.head().to_string(index=False))\n","\n","    return export_df['Ticker'].tolist()"],"metadata":{"id":"3C90VVOw6DrA","executionInfo":{"status":"ok","timestamp":1768931214153,"user_tz":300,"elapsed":23,"user":{"displayName":"Brendan Dyson","userId":"17814213712681171988"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# ============================================================\n","# USAGE\n","# ============================================================\n","\n","lawyer_name = \"mitchell bloom\"\n","df = search_lawyer(lawyer_name)\n","\n","if not df.empty:\n","    filename = f\"{lawyer_name.lower().replace(' ', '_')}_tickers.csv\"\n","    tickers = export_tickers_csv(df, filename)"],"metadata":{"id":"da3vg6n3r2dI","executionInfo":{"status":"ok","timestamp":1768931457799,"user_tz":300,"elapsed":5845,"user":{"displayName":"Brendan Dyson","userId":"17814213712681171988"}},"outputId":"7cfa4820-472a-4837-cdf3-0daa30bcd0ff","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","SEARCHING LAWYER: mitchell bloom\n","======================================================================\n","\n","Testing volume for 'mitchell bloom'...\n","  2 years: 2 unique companies\n","  4 years: 2 unique companies\n","LOW VOLUME - Using 7 years for better coverage\n","\n","Final search: 2019-01-22 to 2026-01-20 (7 years)\n","\n","Total filings found: 92\n","After filtering to relevant filing types: 30\n","Unique companies: 7\n","\n","✓ Search complete: 4 companies with tickers\n","\n","✓ Exported to: mitchell_bloom_tickers.csv\n","✓ Total companies: 4\n","\n","First 5 entries:\n","                         Company         Ticker Date of most recent filing for this company\n","        Akero Therapeutics, Inc. AKRO US Equity                                  2020-07-07\n","Black Diamond Therapeutics, Inc. BDTX US Equity                                  2020-01-29\n","      Fulcrum Therapeutics, Inc. FULC US Equity                                  2025-02-25\n","                   AVROBIO, Inc. TECX US Equity                                  2024-04-29\n"]}]}]}